# Relatório de Estudos

**Nome do Estagiário:** Carlos Eduardo Pereira de Oliveira 
**Data:** 07/08/2024

**Módulos/Etapas Feitas:**  
1. **Modelagem de Dados**
2. **Analítico**
3. **Transacioal** 
4. **BigQuery**
5. **Linguagem e Framework**

## Resumo dos módulos 

### **Modelagem de Dados**

Modelagem de dados visa organizar todos os dados de maneira eficiente para que possa ser manipulados corretamente. 

Para gerenciamento de dados estruturados é bom usar sistemas que gerencia o banco de dados porque tem uma padronização de acesso, segurança, integridade das informações e performance e escabilidade. Tudo isso é importante para manter um acesso que nem todos poder ter, por isso, existe a segurança para combater hakers, ataques ciberneticos, onde tambem mantem a performance de tudo sendo executado da melhor maneira possível.

No SQL podemos usar gerenciamento e fazer diagramas de entidade relacional, é uma ferramenta para podermos organizar os dados, temos também o modelo lógico, onde separamos e colocamos qual o tipo de dados, atributos e relações entre as entidades, chaves primárias e estrangeiras. Por fim, temos o modelo físico, é como esse modelo será implementado em um sistema de banco de dados especifico.

No NoSQL tem varias estruturas para organizar os dados, estruturas de coleções e documentos, chave e valor, colunar e grafos.

Um exemplo, é sobre o documento, é onde as tabelas serão coleções, ou seja, pasta, nessas pastas da para guardar diferentes documentos, os dados são mais flexíveis.

Diferenças: SQL é uma estrutura mais rigida, focados em relações entre tabelas. É bom para consultas mais completas e juntar duas tambelas. Em NoSQL, pode ter alguns campos e outros não, é mais fexível, e nao é bom fazer junção de tabela, mas é bom para performance.

### **Analítico**

O Modelo Analítico tem como objetivo de apoiar decisão em gerar informações analítica, relatórios, e dados para apoiar a tomada de decisão. Carrega dados produzidos de várias fontes. Se faz inclusão e consulta. No analítico não existem leituras sujas, o dado não esta sendo atualizado, uma vez que só se inclui a consulta. Neste modelo ele mantém o histórico e também tem redundância, por isso, o volume sempre sera maior que o transacional. No analítico o objetivo é informação de qualidade, porque é orientado a negócio.

Portanto o modelo analítico é ideal pra apoio de decisão. Esse modelo responde a perguntas, por exemplo, quem vende mais? que cliente retornaram? qual a margem por produto? que campanhas foram mais efetivas? 

### **Transacional** 

O Modelo Transacional tem como objetivo de manter operações. Onde se produz dados, e suas principais operações são a consulta, inclusão, exclusão, atualização. neste modelo não mantém histórico, se atualizar as informações de um cliente, os dados do histórico somem, não mantem redundância ou tem pouca, minima, os dados não são repetidos, por isso, pode ter grande volume. O transacional procura manter a integridade, por exemplo, você não pode ter venda repetida, porque é orientada a processo.

Portanto modelo transacional é voltado para minimizar redundância e manter integridade. Esse modelo é para registrar a venda e manter o processo, a operação de venda funcionando.

Onde é usado:
- Banco e Finanças: Para gestão de contas, processamentos de pagamentos, transações.
- Ecommerce: Gerenciamento de pedidos, processamentos de pagamentos, gestão e inventário.
- Saúde: Agendamento de consultas, gestão de paciente e registro eletrônico de saúde.

### **Big Query** 

Big Query é o seviço de big data da Google, que é onde consegue armazernar seus dados na nuvem da Google, na prática é como se fosse um banco de dados, de banco de dados, porque pode conectar diversas fontes de dados, de informações e deixar centralizadono big query. Algumas empresas pode utilizar o big query ate como um Data Warehouse.

- Data Warehouse - É uma coleção de dados orientados por assunto, integrado , variável com o tempo e não volátil, que tem por obejtivo dar suporte aos processos de tomada de decisão.

O armazem de dados (DW), é orientado pelos principais assuntos, a modelagem é organizada de acordo com o assunto. 

O sistema transacional gera muitor dados no dia a dia, após isso, entra em um sistema Extract Transform Load (ETL), extrai, transforma e carregam isso para o DW atrasves de blocos conhecido como Data Market, que vão organizar isso como cada assunto. 

### **Linguagem e Framework** 

Python é uma linguagem com um propoito geral, é uma liguagem que da para usar como basicamente tudo, é uma linguagem que foi criada para ser simple e intuitiva, é também uma linguagem multiplataforma. É uma liguagem que ja vem com muitos pacotes instalados, e é código aberto, extremamente organizada e orientada a objetos.

Principais areas de aplicação:

Tem lugares que a linguagem python se torna muito poderosa, por exemplo, os números são muitos grandes, o python suporta esses números grandes, conseguindo fazer muitos cálculos, isso ajuda muito na evolução e Inteligência Artificial, Biotecnologia, Computação 3D.

Algumas empresas que usam python:

 - Zope. Air Canada. BitTorret. Globo. Google. YouTube. Nasa

Jogos criados em python:
- Frets on Fire. Jewel Quest. EVE Online. Civilization IV. Battlefield 2.

Framework

Um exemplo de framework da linguagem python, é o Apache Spark que é utilizado em grande escala para análise de dados, projetado para processamento de dado sistribuido em cluster, em memoria, é veloz, escalável e trabalha com um sistema de participionamento.

Outro caracteristicas do Spark é o Paticionamento, particionar dados, é divivir dados no cluster, e não é o mesmo que na replicação. Na replicação da para copiar dados na rede, no particionamento da para pegar o mesmo conjunto de dados e divido ele para colocar em partes do mesmo dado diferentes nós da rede.

Quando utiliza python com spark, todas a bibliotecas usada em python pode usar junto, ponde usar panda, pode utilizar qualquer coisa ao mesmo tempo que o spark.

O spark é formado por quatro principais componentes:

- Machine Learning (Mllib) - da para criar modelos de machine learning com bibliotecas nativas do spark.
- SQL (Spark SQL) - permite que importe dados que persiste dados em formato de big data, como parquet ou rc, da para consultar esses dados usando comando SQL, é uma linguagem semelhante a que usa em outros bancos de dados.
- Processamento em Streaming - Processamento em streaming são aquelas aplicações que os dados precisam ser processados a medida que os dados são produzidos em tempo real, proximo ao tempo real.
- Processamento de Grafos (GraphX) - Com ele, é possível realizar operações complexas sobre grafos, tais como busca de padrões, análise de comunidades e cálculo de centralidades, de maneira eficiente e escalável.

## Links de Laboratórios (se houver)
- [Curso Youtube - Curso Modelagem de Dados e SQL](https://www.youtube.com/watch?v=SEnnucNP1h0)
- [Curso Udemy - Engenharia de Dados: Domine o Big Data](https://www.udemy.com/course/engenheiro-de-dados/?couponCode=KEEPLEARNING)
- [Youtube - Video Big Query](https://www.youtube.com/watch?v=fZkEDWTSfB0)
- [Youtube - Curso de Python](https://www.youtube.com/watch?v=S9uPNppGsGo)
- [Udemy - Apache Spark](https://www.udemy.com/course/engenheiro-de-dados/learn/lecture/34024166#overview)

**Recursos Utilizados:**  
- Diagrama de Entidade Relacional.
- SQL.
- NoSQL.
- Google
- Python
- PyCharm (IDE)
- Colab (IDE)

**Principais comandos: (se aplicável)**  
- CREATE - criar tabela.
- SELECT - selecionar dado da tabela.
- print.
- input.


**Desafios Encontrados:**  
Entender e saber diferenciar o banco de dados SQL e NoSQL.
Entender o conceito de modelo analítico e transacional.

**Feedback e Ajustes:**  
Após ver o video da trilha de conhecimento, pude entender esses conceitos.
Com o template ajudou bastante a organizar o relatório.

**Próximos Passos:**  
Seguir estudando e praticando para se desenvolver.
Continuar a trilha de estudo (Mensageria ...).